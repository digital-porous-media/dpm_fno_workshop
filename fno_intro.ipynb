{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "250c5ed2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Introduction to Fourier Neural Operators (FNOs)\n",
    "---\n",
    "**Authors**: Xuesong (Cedar) Ma, Bernard Chang, and Masa Prodanovic\n",
    "\n",
    "Last Updated: Apr. 30, 2025\n",
    "\n",
    "## Objective\n",
    "In this notebook, we will introduce the components of a ***Fourier Neural Operator (FNO)***. Both a 2D and 3D versions of the FNO will be introduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e680ec7d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3253b3c2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Neural Operators\n",
    "\n",
    "Neural Operators are mappings across discretized function spaces and aim to solve entire parametric families of Partial Differential Equations. In this workshop, we will demonstrate their capabilities through two key applications:\n",
    "\n",
    "* Predicting static solution fields from input coefficients (e.g., material properties or source terms)\n",
    "* Mapping from an initial condition to the solution function at a later temporal point\n",
    "\n",
    "### Background\n",
    "In mathematical terms, integral operators can be written as,\n",
    "\n",
    "$(\\mathcal{G}a)(x) = \\int_{\\Omega} K(x, y)a(y)dy$.\n",
    "\n",
    "Neural operators learn to approximate the kernel function $K(x, y)$. The difference between Neural Operator architectures lies in how they represent the integral operator.\n",
    "\n",
    "<img src=\"images/neuraloperator.svg\" />\n",
    "\n",
    "\n",
    "\n",
    "Examples of Neural Operators include:\n",
    "\n",
    "* DeepONet [[1]](https://doi.org/10.1038/s42256-021-00302-5)\n",
    "* Fourier Neural Operators [[2]](https://doi.org/10.48550/arXiv.2010.08895)\n",
    "* Graph Neural Operators [[3]](https://doi.org/10.48550/arXiv.2003.03485)\n",
    "* Transformer Neural Operators [[4]](https://doi.org/10.48550/arXiv.2405.19166)\n",
    "* ...\n",
    "\n",
    "***Note***: Neural operators do not explicitly parameterize $K(x,y)$. Rather, they learn a computational representation that acts like applying the kernel.\n",
    "\n",
    "\n",
    "**Fourier Neural Operators** are a special class of Neural Operators that leverage the Fast Fourier Transform (FFT) to perform spectral convolution, enabling them to capture long-range dependencies and global structures in the input function space.\n",
    "\n",
    "FNOs notably enable **zero-shot superresolution** â€” they can generalize to higher resolution discretizations at inference time.\n",
    "\n",
    "<img src=\"images/fno_architecture.png\" width=\"800\"/>\n",
    "\n",
    "\n",
    "## FNO Components\n",
    "The FNO architecture is not significantly different from traditional neural networks. They are comprised of three main components:\n",
    "\n",
    "1. **Lifting (Encoding) Block**: Maps the input function to a higher-dimensional space.\n",
    "    - This is most commonly an affine transformation (nn.Linear).\n",
    "    - It *could* be more complex (e.g., MLP, Convolutions, etc.)\n",
    "2. **Fourier Blocks**: Performs spectral convolutions and learns key information in latent space.\n",
    "3. **Projection (Decoding) Block**: Maps the latent space back to the original function space.\n",
    "    - This is commonly two affine transformations (with an activation in between).\n",
    "\n",
    "Here, we will start building the FNO architecture by implementing the spectral branch.\n",
    "\n",
    "### Fourier Blocks\n",
    "\n",
    "A Fourier block is a layer that has two branches:\n",
    "\n",
    "1. *Spectral branch* - Learns global features via FFT\n",
    "    - Transforms the input into Fourier space via FFT.\n",
    "    - Applies learned weights in frequency space (spectral convolution)\n",
    "    - Transforms the output back into the original space via inverse FFT.\n",
    "2. *Spatial branch* - Learns local features via convolution\n",
    "\n",
    "These two branches are added together and put through a non-linear activation function (e.g., ReLU).\n",
    "\n",
    "#### Spectral Convolution\n",
    "\n",
    "\n",
    "<img src=\"images/spectral_conv.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60220bf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SpectralConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, modes1, modes2):\n",
    "        \"\"\"\n",
    "        Spectral convolution layer. Performs FFT, linear transform, and Inverse FFT.\n",
    "\n",
    "        Parameters:\n",
    "        ---\n",
    "        in_channels : int,\n",
    "            Number of layer input channels\n",
    "        out_channels : int\n",
    "            Number of layer output channels\n",
    "        modes1 : int\n",
    "            Number of Fourier modes to keep in the first dimension\n",
    "        modes2 : int\n",
    "            Number of Fourier modes to keep in the second dimension\n",
    "        \"\"\"\n",
    "        super(SpectralConv2d, self).__init__()\n",
    "\n",
    "        # Number of input channels (features)\n",
    "        self.in_channels = in_channels\n",
    "        # Number of output channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        # Number of Fourier modes to multiply in each dimension. Maximum floor(N/2) + 1\n",
    "        self.modes1 = modes1\n",
    "        self.modes2 = modes2\n",
    "\n",
    "        # Initialize parameter weights\n",
    "        self.scale = (1 / (self.in_channels * self.out_channels))\n",
    "        self.weights1 = nn.Parameter(\n",
    "            self.scale * torch.rand(self.in_channels, self.out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
    "        self.weights2 = nn.Parameter(\n",
    "            self.scale * torch.rand(self.in_channels, self.out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        # Compute FFT.\n",
    "        # Note change in dimension from (batch_size, channels, x, y) to (batch_size, channels, x, y//2 + 1)\n",
    "        # FFT output is Hermitian symmetric, so we should take the first modes1 and last modes1 to get low frequency components.\n",
    "        x_ft = torch.fft.rfft2(x)\n",
    "        # Initialize output FFT tensor\n",
    "        out_ft = torch.zeros(batchsize, self.out_channels,\n",
    "                             x.size(-2), x.size(-1) // 2 + 1, dtype=torch.cfloat, device=x.device)\n",
    "        # Perform complex multiplication on lower Fourier modes\n",
    "        out_ft[:, :, :self.modes1, :self.modes2] = \\\n",
    "            self.complex_multiplication2d(\n",
    "                x_ft[:, :, :self.modes1, :self.modes2], self.weights1)\n",
    "        out_ft[:, :, -self.modes1:, :self.modes2] = \\\n",
    "            self.complex_multiplication2d(\n",
    "                x_ft[:, :, -self.modes1:, :self.modes2], self.weights2)\n",
    "\n",
    "        # Return to physical space\n",
    "        x = torch.fft.irfft2(out_ft, s=(x.size(-2), x.size(-1)))\n",
    "        return x\n",
    "    @staticmethod\n",
    "    def complex_multiplication2d(a, b):\n",
    "        \"\"\"\n",
    "        Complex 2D multiplication between input tensor `a` and weight tensor `b`.\n",
    "\n",
    "        Parameters:\n",
    "        ---\n",
    "        a: torch.Tensor,\n",
    "            Complex input tensor of shape (batch_size, in_channels, x, y)\n",
    "\n",
    "        b: torch.Tensor, shape (in_channel, out_channel, x, y)\n",
    "            Complex weight tensor of shape (in_channels, out_channels, x, y)\n",
    "\n",
    "        Returns:\n",
    "        ---\n",
    "        torch.Tensor\n",
    "            Complex output tensor of shape (batch_size, out_channels, x, y)\n",
    "        \"\"\"\n",
    "        # Sum over in_channels dimension\n",
    "        return torch.einsum('bixy,ioxy->boxy', a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92626285",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Fourier Layer\n",
    "\n",
    "<img src=\"images/fno_block.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f557765",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourierBlock2D(nn.Module):\n",
    "    \"\"\"\n",
    "    Single FNO block with spectral convolution, Conv2D, and activation function.\n",
    "\n",
    "    This block performs the following operations:\n",
    "    1. Applies a Fourier-based spectral convolution.\n",
    "    2. Applies a 1x1 convolution in the spatial domain.\n",
    "    3. Adds a residual connection between the two.\n",
    "    4. Applies a GELU activation function.\n",
    "\n",
    "    Parameters:\n",
    "    ---\n",
    "        width: int,\n",
    "            Number of block input/output channels.\n",
    "        modes1: int,\n",
    "            Number of Fourier modes to use in the first dimension.\n",
    "        modes2: int,\n",
    "            Number of Fourier modes to use in the second dimension.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, width, modes1, modes2):\n",
    "        super(FourierBlock2D, self).__init__()\n",
    "        self.spectral_conv = SpectralConv2d(width, width, modes1, modes2)\n",
    "        self.w = nn.Conv2d(width, width, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        x1 = self.spectral_conv(x)\n",
    "        x2 = self.w(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f6938b",
   "metadata": {},
   "source": [
    "### Full 2D Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24d9cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNO2D(nn.Module):\n",
    "    \"\"\"\n",
    "    Full FNO network. It contains `num_layers` FNO blocks.\n",
    "\n",
    "    This network performs the following operations:\n",
    "    1. Lift the input channels to the desired number of channels\n",
    "    2. Perform `num_layers` layers of the integral operators v' = (W + K)(v)\n",
    "    3. Project the channel space to the output space\n",
    "\n",
    "    Input:\n",
    "    ---\n",
    "        torch.Tensor, shape (batch_size, x, y, channels=3)\n",
    "            Coefficients or initial condition and locations (a(x, y), x, y)\n",
    "    Output:\n",
    "    ---\n",
    "        torch.Tensor, shape (batch_size, x, y, channels=1)\n",
    "            Predicted solution\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, net_name=\"FNO2D\", width=32, num_layers=4, modes1=8, modes2=8, lr=5e-4, hidden_p_channels=128):\n",
    "        super(FNO2D, self).__init__()\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        ---\n",
    "            width: int,\n",
    "                Number of higher-dimensional channels. Default = 20.\n",
    "            num_layers: int,\n",
    "                Number of FNO blocks in the network. Default = 4.\n",
    "            modes1: int,\n",
    "                Number of Fourier modes to use in the first dimension. Default = 8.\n",
    "            modes2: int,\n",
    "                Number of Fourier modes to use in the second dimension. Default = 8.\n",
    "            hidden_p_channels: int,\n",
    "                Number of channels for the hidden layer in the projecting step. Default = 128.\n",
    "        \"\"\"\n",
    "        self.net_name = net_name\n",
    "        self.modes1 = modes1\n",
    "        self.modes2 = modes2\n",
    "        self.width = width\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_p_channels = hidden_p_channels\n",
    "        self.lr = lr\n",
    "        self.padding = 6\n",
    "\n",
    "        # Define affine transformation to lift 3 channels to `width` channels\n",
    "        self.p = nn.Linear(3, self.width)\n",
    "\n",
    "        # Define a list of FourierBlock2D layers\n",
    "        self.fno_blocks = nn.ModuleList([\n",
    "            FourierBlock2D(self.width, self.modes1, self.modes2) for _ in range(self.num_layers)\n",
    "        ])\n",
    "\n",
    "        # Define affine transformations to project the channel space to the output space\n",
    "        self.q1 = nn.Linear(self.width, self.hidden_p_channels)\n",
    "        self.q2 = nn.Linear(self.hidden_p_channels, 1)\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Get the grid of x\n",
    "        grid = self.get_grid(x.shape, x.device)\n",
    "        # Concatenate the grid to the input tensor\n",
    "        x = torch.cat((x, grid), dim=-1)\n",
    "\n",
    "        # Lift input\n",
    "        x = self.p(x)\n",
    "        # Permute the dimensions from (batch_size, x, y, channels) to (batch_size, channels, x, y)\n",
    "        # nn.Linear operates on the last dimension\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "\n",
    "        # Perform Fourier-based spectral convolution and activation\n",
    "        for layer in self.fno_blocks:\n",
    "            x = layer(x)\n",
    "\n",
    "        # Permute the dimensions from (batch_size, x, y, channels) to (batch_size, channels, x, y)\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "\n",
    "        # Project the channel space to the output space\n",
    "        x = self.q1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.q2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def get_grid(shape, device):\n",
    "        batchsize, size_x, size_y = shape[:-1]\n",
    "        # Create grid for x and y coordinates using PyTorch\n",
    "        gridx = torch.linspace(0, 1, steps=size_x).reshape(\n",
    "            1, size_x, 1, 1).repeat([batchsize, 1, size_y, 1])\n",
    "        gridy = torch.linspace(0, 1, steps=size_y).reshape(\n",
    "            1, 1, size_y, 1).repeat([batchsize, size_x, 1, 1])\n",
    "        return torch.cat((gridx, gridy), dim=-1).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a402a2e8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 3D Architecture\n",
    "\n",
    "This architecture applies to both 2D + time and 3D static problems.\n",
    "\n",
    "### Spectral Convolution (3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3822bb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralConv3d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, modes1, modes2, modes3):\n",
    "        super(SpectralConv3d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        Spectral convolution layer. Performs FFT, linear transform, and Inverse FFT.\n",
    "\n",
    "        Parameters:\n",
    "        ---\n",
    "        in_channels : int,\n",
    "            Number of layer input channels\n",
    "        out_channels : int\n",
    "            Number of layer output channels\n",
    "        modes1 : int\n",
    "            Number of Fourier modes to keep in the first dimension\n",
    "        modes2 : int\n",
    "            Number of Fourier modes to keep in the second dimension\n",
    "        modes3 : int\n",
    "            Number of Fourier modes to keep in the third dimension\n",
    "        \"\"\"\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        # Number of Fourier modes to multiply in each dimension. Maximum floor(N/2) + 1\n",
    "        self.modes1 = modes1\n",
    "        self.modes2 = modes2\n",
    "        self.modes3 = modes3\n",
    "\n",
    "        self.scale = (1 / (in_channels * out_channels))\n",
    "        self.weights1 = nn.Parameter(\n",
    "            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, dtype=torch.cfloat))\n",
    "        self.weights2 = nn.Parameter(\n",
    "            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, dtype=torch.cfloat))\n",
    "        self.weights3 = nn.Parameter(\n",
    "            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, dtype=torch.cfloat))\n",
    "        self.weights4 = nn.Parameter(\n",
    "            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, dtype=torch.cfloat))\n",
    "\n",
    "    # Complex multiplication\n",
    "    @staticmethod\n",
    "    def complex_multiplication3d(a, b):\n",
    "        # (batch, in_channel, x,y,z), (in_channel, out_channel, x,y,z) -> (batch, out_channel, x,y,z)\n",
    "        return torch.einsum(\"bixyz,ioxyz->boxyz\", a, b)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        # Compute FFT.\n",
    "        # Note change in dimension from (batch_size, channels, x, y) to (batch_size, channels, x, y//2 + 1)\n",
    "        # FFT output is Hermitian symmetric, so we should take the first modes1/modes2 and last modes1/modes2 to get low frequency components.\n",
    "        x_ft = torch.fft.rfftn(x, dim=[-3, -2, -1])\n",
    "\n",
    "        # Multiply relevant Fourier modes\n",
    "        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-3), x.size(-2), x.size(-1) // 2 + 1, dtype=torch.cfloat, device=x.device)\n",
    "        out_ft[:, :, :self.modes1, :self.modes2, :self.modes3] = \\\n",
    "            self.complex_multiplication3d(x_ft[:, :, :self.modes1, :self.modes2, :self.modes3], self.weights1)\n",
    "        out_ft[:, :, -self.modes1:, :self.modes2, :self.modes3] = \\\n",
    "            self.complex_multiplication3d(x_ft[:, :, -self.modes1:, :self.modes2, :self.modes3], self.weights2)\n",
    "        out_ft[:, :, :self.modes1, -self.modes2:, :self.modes3] = \\\n",
    "            self.complex_multiplication3d(x_ft[:, :, :self.modes1, -self.modes2:, :self.modes3], self.weights3)\n",
    "        out_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3] = \\\n",
    "            self.complex_multiplication3d(x_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3], self.weights4)\n",
    "\n",
    "        # Return to physical space\n",
    "        x = torch.fft.irfftn(out_ft, s=(x.size(-3), x.size(-2), x.size(-1)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274a56f9",
   "metadata": {},
   "source": [
    "### FNO Layer (3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8e22e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourierBlock3D(nn.Module):\n",
    "    \"\"\"\n",
    "    Single FNO block with spectral convolution, Conv3D, and activation function.\n",
    "\n",
    "    This block performs the following operations:\n",
    "    1. Applies a Fourier-based spectral convolution.\n",
    "    2. Applies a 1x1 convolution in the spatial domain.\n",
    "    3. Adds a residual connection between the two.\n",
    "    4. Applies a GELU activation function.\n",
    "\n",
    "    Parameters:\n",
    "    ---\n",
    "        width: int,\n",
    "            Number of block input/output channels.\n",
    "        modes1: int,\n",
    "            Number of Fourier modes to use in the first dimension.\n",
    "        modes2: int,\n",
    "            Number of Fourier modes to use in the second dimension.\n",
    "        modes3: int,\n",
    "            Number of Fourier modes to use in the third dimension.\n",
    "    \"\"\"\n",
    "    def __init__(self, width, modes1, modes2, modes3):\n",
    "        super(FourierBlock3D, self).__init__()\n",
    "        self.spectral_conv = SpectralConv3d(width, width, modes1, modes2, modes3)\n",
    "        self.w = nn.Conv3d(width, width, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        x1 = self.spectral_conv(x)\n",
    "        x2 = self.w(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9e8421",
   "metadata": {},
   "source": [
    "### Full 3D Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e652ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNO3D(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 net_name='FNO3DModel',\n",
    "                 in_channels=10,\n",
    "                 out_channels=3,\n",
    "                 modes1=8,\n",
    "                 modes2=8,\n",
    "                 modes3=8,\n",
    "                 width=20,\n",
    "                 num_layers=4,\n",
    "                 lr=1e-3,\n",
    "                 ):\n",
    "\n",
    "        super(FNO3D, self).__init__()\n",
    "        self.net_name = net_name\n",
    "\n",
    "        self.input_channels = in_channels\n",
    "        self.output_channels = out_channels\n",
    "        self.modes1 = modes1\n",
    "        self.modes2 = modes2\n",
    "        self.modes3 = modes3\n",
    "        self.width = width\n",
    "        self.num_layers = num_layers\n",
    "        self.lr = lr\n",
    "\n",
    "        self.padding = 6\n",
    "\n",
    "        self.p = nn.Linear(self.input_channels + 3, self.width)  # input channel is 3: (sigma(x, y, z), x, y, z)\n",
    "\n",
    "        self.fno_blocks = nn.ModuleList([\n",
    "            FourierBlock3D(self.width, self.modes1, self.modes2, self.modes3) for _ in range(self.num_layers)\n",
    "        ])\n",
    "\n",
    "        self.q1 = nn.Linear(self.width, self.width * 4)\n",
    "        self.q2 = nn.Linear(self.width * 4, self.output_channels)\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Get the grid of x\n",
    "        grid = self.get_grid(x.shape, x.device)\n",
    "        x = torch.cat((x, grid), dim=-1)\n",
    "\n",
    "        # Lift input\n",
    "        x = self.p(x)\n",
    "\n",
    "        # Permute the dimensions from (batch_size, x, y, z, channels) to (batch_size, channels, x, y, z)\n",
    "        # nn.Linear operates on the last dimension\n",
    "        x = x.permute(0, 4, 1, 2, 3)\n",
    "        x = F.pad(x, [0, self.padding])\n",
    "\n",
    "        for layer in self.fno_blocks:\n",
    "            x = layer(x)\n",
    "\n",
    "        x = x[..., :-self.padding]\n",
    "        x = x.permute(0, 2, 3, 4, 1)\n",
    "        x = self.q1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.q2(x)\n",
    "\n",
    "        return x.float()\n",
    "\n",
    "    @staticmethod\n",
    "    def get_grid(shape, device):\n",
    "        batchsize, size_x, size_y, size_z = shape[:-1]\n",
    "        gridx = torch.linspace(0, 1, steps=size_x, dtype=torch.float, device=device)\n",
    "        gridy = torch.linspace(0, 1, steps=size_y, dtype=torch.float, device=device)\n",
    "        gridz = torch.linspace(0, 1, steps=size_z, dtype=torch.float, device=device)\n",
    "\n",
    "        gridx = gridx.view(1, size_x, 1, 1, 1).expand(batchsize, -1, size_y, size_z, -1)\n",
    "        gridy = gridy.view(1, 1, size_y, 1, 1).expand(batchsize, size_x, -1, size_z, -1)\n",
    "        gridz = gridz.view(1, 1, 1, size_z, 1).expand(batchsize, size_x, size_y, -1, -1)\n",
    "        return torch.cat((gridx, gridy, gridz), dim=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
